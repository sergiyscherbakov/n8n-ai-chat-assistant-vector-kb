# AI Chat Assistant з векторною базою знань для n8n

## Опис

Цей проект містить готовий workflow для створення AI чат-асистента з пошуком у векторній базі знань.

Шаблон дозволяє швидко запустити агента в n8n, який:
- відповідає українською у дружньому, жартівливому стилі;
- завжди шукає інформацію у векторній базі знань;
- підключає модель gpt-5-nano для генерації відповідей;
- пам'ятає контекст діалогу (Simple Memory);
- може працювати з PDF та зображеннями (витяг тексту й опис картинок).

## Схема Workflow

Workflow складається з двох частин:

### Частина 1: Підготовка бази знань (Data Ingestion)
```
HTTP Request (PDF) → Extract from File ─┐
                                         ├─→ Merge → Default Data Loader → Simple Vector Store
HTTP Request (Image) → Analyze image ───┘                ↑                        ↑
                                                          |                        |
                                    Recursive Character Text Splitter    Embeddings OpenAI
```

### Частина 2: Чат-інтерфейс (Chat Interface)
```
When chat message received → AI Agent
                                ↑
                                |
               ┌────────────────┼─────────────────────┐
               |                |                     |
    OpenAI Chat Model    Simple Memory         test_SVDB (Vector Store)
                                                      ↑
                                                      |
                                              Embeddings OpenAI
```

---

## Детальний опис нод

### ЧАСТИНА 1: ПІДГОТОВКА БАЗИ ЗНАНЬ

#### 1. HTTP Request (для PDF)

**Призначення:** Завантажує PDF файл з інтернету

**Параметри для налаштування:**
- **URL**: `https://ai-2027.com/ai-2027.pdf` (замініть на свій URL)
- **Method**: GET (за замовчуванням)

**Що змінити:**
- Вставте URL вашого PDF файлу
- Можна додати кілька HTTP Request нод для різних PDF файлів

**Вхід:** Немає (запускається вручну)

**Вихід:**
```json
{
  "data": "<binary_pdf_data>",
  "headers": {
    "content-type": "application/pdf"
  }
}
```

---

#### 2. Extract from File

**Призначення:** Витягує текст з PDF файлу

**Параметри для налаштування:**
- **Operation**: `pdf`
- **Options**: За замовчуванням

**Що це робить:**
- Парсить PDF
- Витягує весь текст
- Зберігає структуру документа

**Вхід:** Binary дані PDF

**Вихід:**
```json
{
  "data": "Повний текст з PDF документа..."
}
```

---

#### 3. HTTP Request1 (для зображення)

**Призначення:** Завантажує зображення з інтернету

**Параметри для налаштування:**
- **URL**: `https://naurok.com.ua/uploads/files/404207/106789/113635_html/images/106789.002.png`

**Що змінити:**
- Вставте URL вашого зображення
- Підтримуються формати: PNG, JPG, JPEG, WebP

**Вхід:** Немає

**Вихід:**
```json
{
  "data": "<binary_image_data>",
  "headers": {
    "content-type": "image/png"
  }
}
```

---

#### 4. Analyze Image (OpenAI Vision)

**Призначення:** Аналізує зображення та витягує текст за допомогою GPT-4 Vision

**Параметри для налаштування:**
- **Resource**: `image`
- **Operation**: `analyze`
- **Model**: `gpt-4o-mini`

**Prompt:**
```
Опиши деталізовано зображення і перепиши весь текст який знаходиться на цьому зображенні.

Відповідь надай у вигляді наступної структури

ОПИС ЗОБРАЖЕННЯ

ТЕКСТ ІЗ ЗОБРАЖЕННЯ
```

**Що це дає:**
- Розпізнає текст на зображенні (OCR)
- Описує візуальний контент
- Витягає всю корисну інформацію

**Що змінити:**
- Налаштуйте prompt під свої потреби
- Оберіть модель (gpt-4o-mini економніший, gpt-4o точніший)

**Вхід:** Binary дані зображення (base64)

**Вихід:**
```json
{
  "data": "ОПИС ЗОБРАЖЕННЯ\nНа зображенні показано...\n\nТЕКСТ ІЗ ЗОБРАЖЕННЯ\nЗаголовок: ...\nТекст: ..."
}
```

---

#### 5. Merge

**Призначення:** Об'єднує результати з PDF та зображення в один потік

**Параметри:**
- **Mode**: `chooseBranch` - вибирає гілку для продовження

**Вхід:**
- Гілка 0: Текст з PDF
- Гілка 1: Опис зображення

**Вихід:** Об'єднані дані

---

#### 6. Recursive Character Text Splitter

**Призначення:** Розбиває великий текст на менші chunk'и для векторизації

**Параметри для налаштування:**
- **Chunk Size**: `800` символів
- **Chunk Overlap**: `400` символів (перекриття між chunk'ами)

**Навіщо потрібен overlap:**
- Зберігає контекст між фрагментами
- Не втрачає інформацію на межах chunk'ів

**Що змінити:**
- Для коротших текстів: зменшити chunk size до 500
- Для довгих технічних документів: збільшити до 1000-1500

**Вхід:** Повний текст

**Вихід:**
```json
[
  {"data": "Перший фрагмент тексту з 800 символів..."},
  {"data": "Другий фрагмент з перекриттям 400 символів..."},
  ...
]
```

---

#### 7. Default Data Loader

**Призначення:** Завантажує текстові дані для векторної бази

**Параметри:**
- **Text Splitting Mode**: `custom` (використовує Recursive Character Text Splitter)

**Вхід:** Розбитий текст

**Вихід:** Документи готові для векторизації

---

#### 8. Embeddings OpenAI1

**Призначення:** Створює векторні embeddings для текстів

**Параметри для налаштування:**
- **Model**: `text-embedding-ada-002` (за замовчуванням)
- **Credentials**: OpenAI API ключ

**Що це робить:**
- Конвертує текст у числові вектори (1536 вимірів)
- Зберігає семантичний зміст тексту

**Вхід:** Текстові документи

**Вихід:** Числові вектори

---

#### 9. Simple Vector Store (Insert Mode)

**Призначення:** Зберігає векторні embeddings в пам'яті

**Параметри для налаштування:**
- **Mode**: `insert`
- **Memory Key**: `vector_store_key` (унікальний ідентифікатор бази)
- **Embedding Batch Size**: `800`

**Що це дає:**
- Створює базу знань в оперативній пам'яті n8n
- Дозволяє швидко шукати релевантну інформацію

**Важливо:**
- Дані зберігаються тільки в оперативній пам'яті
- При перезапуску n8n базу треба заповнити знову
- Для персистентного зберігання використовуйте Pinecone або Qdrant

**Вхід:** Документи + Embeddings

**Вихід:** Збережена векторна база

---

### ЧАСТИНА 2: ЧАТ-ІНТЕРФЕЙС

#### 10. When Chat Message Received (Chat Trigger)

**Призначення:** Створює веб-інтерфейс для спілкування з агентом

**Параметри:**
- **Webhook ID**: Унікальний ID для чату

**Як отримати посилання на чат:**
1. Після активації workflow
2. Скопіюйте URL з Production URL
3. Відкрийте цей URL в браузері

**Вхід:** Повідомлення користувача через веб-інтерфейс

**Вихід:**
```json
{
  "chatInput": "Питання користувача",
  "sessionId": "unique-session-id"
}
```

---

#### 11. AI Agent (Головний агент)

**Призначення:** Координує роботу чат-бота та пошук в базі знань

**Параметри для налаштування:**

**System Message:**
```
Ти комедійний асистент, який дружньо і пощитивно відповідає на запити користувача

ЗАВЖДИ ШУКАЙ інформацію із векторної бази і використовуй інструмент "test_SVDB" для пошуку інформації для КОЖНОГО ЗАПИТУ КОРИСТУВАЧА

Відповідь надай УКРАЇНІСЬКОЮ мовою
```

**Що змінити:**
- Налаштуйте стиль відповідей (комедійний → професійний, дружній, формальний)
- Змініть мову відповідей
- Додайте спеціалізацію (експерт з маркетингу, технічний консультант, і т.д.)

**Приклади System Message:**

**Для технічної підтримки:**
```
Ти професійний технічний консультант. Відповідай чітко та структуровано.

ЗАВЖДИ ШУКАЙ інформацію в базі знань використовуючи інструмент "test_SVDB".

Якщо інформації немає в базі - чесно повідом про це.

Відповідь надавай УКРАЇНСЬКОЮ мовою.
```

**Для освітнього асистента:**
```
Ти досвідчений викладач, який пояснює складні теми простою мовою.

Завжди шукай інформацію в базі знань через інструмент "test_SVDB".

Структуруй відповіді з прикладами та поясненнями.

Відповідай УКРАЇНСЬКОЮ мовою.
```

**Вхід:** Запит користувача

**Вихід:** Згенерована відповідь

---

#### 12. OpenAI Chat Model

**Призначення:** Мовна модель для генерації відповідей

**Параметри для налаштування:**
- **Model**: `gpt-5-nano` (замініть на актуальну модель)
- **Credentials**: OpenAI API ключ

**Доступні моделі:**
- `gpt-4o` - найпотужніша, найдорожча
- `gpt-4o-mini` - швидка та економна (рекомендується)
- `gpt-3.5-turbo` - найдешевша, базова якість

**Вхід:** Промпт від AI Agent

**Вихід:** Згенерована відповідь

---

#### 13. Simple Memory (Window Buffer Memory)

**Призначення:** Зберігає історію діалогу

**Параметри для налаштування:**
- **Context Window Length**: `20` повідомлень

**Що зберігається:**
- Останні 20 повідомлень (запити + відповіді)
- Контекст розмови для кожної сесії

**Що змінити:**
- Для коротких діалогів: `10` повідомлень
- Для довгих консультацій: `50` повідомлень
- Увага: більше повідомлень = більше токенів = більша вартість

**Вхід:** Кожне нове повідомлення

**Вихід:** Історія діалогу

---

#### 14. test_SVDB (Vector Store Retrieval)

**Призначення:** Шукає релевантну інформацію в векторній базі знань

**Параметри для налаштування:**
- **Mode**: `retrieve-as-tool`
- **Tool Description**: `ПОШУК ІНФОРМАЦІЇ в векторній базі знань`
- **Memory Key**: `vector_store_key` (має збігатися з Insert Mode)
- **Top K**: `5` (кількість найрелевантніших результатів)

**Як працює пошук:**
1. AI Agent отримує запит користувача
2. Запит конвертується в embedding вектор
3. Шукає 5 найближчих векторів в базі (cosine similarity)
4. Повертає текст з цих фрагментів
5. AI Agent використовує знайдену інформацію для відповіді

**Що змінити:**
- **Top K = 3**: для коротких відповідей
- **Top K = 10**: для комплексних запитів з багатьма темами

**Вхід:** Запит користувача (текст)

**Вихід:**
```json
{
  "results": [
    {
      "content": "Релевантний текст з бази знань...",
      "score": 0.89
    },
    ...
  ]
}
```

---

#### 15. Embeddings OpenAI (для пошуку)

**Призначення:** Створює embedding для запиту користувача

**Параметри:**
- **Model**: `text-embedding-ada-002`
- **Credentials**: OpenAI API ключ (той же що для вставки)

**Важливо:** Має використовувати ту ж саму модель embeddings, що і для вставки даних!

**Вхід:** Текст запиту

**Вихід:** Вектор запиту для пошуку

---

## Інструкція з налаштування

### Крок 1: Імпорт Workflow

1. Завантажте файл `My Agent Personal-4.json`
2. Відкрийте n8n
3. Виберіть: **Workflows** → **Import from File**
4. Додайте файл `My Agent Personal-4.json`

### Крок 2: Налаштування OpenAI API ключів

1. Отримайте API ключ на https://platform.openai.com/api-keys
2. В n8n перейдіть до **Credentials** → **Create New**
3. Оберіть **OpenAI API**
4. Вставте ключ
5. Застосуйте цей ключ до всіх OpenAI нод:
   - OpenAI Chat Model
   - Embeddings OpenAI
   - Embeddings OpenAI1
   - Analyze image

### Крок 3: Налаштування джерел даних

**Для PDF:**
1. Клікніть на **HTTP Request** (верхня нода)
2. Замініть URL на ваш PDF файл
3. Можна додати кілька HTTP Request нод для різних PDF

**Для зображень:**
1. Клікніть на **HTTP Request1**
2. Замініть URL на ваше зображення
3. В **Analyze image** налаштуйте prompt для розпізнавання

**Для локальних файлів:**
Замість HTTP Request використайте **Read Binary File** ноду

### Крок 4: Заповнення бази знань

**ВАЖЛИВО:** Спочатку треба заповнити векторну базу!

1. Виділіть ноди з Частини 1 (Data Ingestion)
2. Клікніть **Execute Workflow** або натисніть на **HTTP Request** → **Test step**
3. Перевірте що дані пройшли через всі ноди до **Simple Vector Store**
4. Дочекайтесь успішного виконання

**Перевірка:**
- Всі ноди мають зелену галочку ✓
- Simple Vector Store показує скільки векторів збережено

### Крок 5: Активація чату

1. Натисніть **Activate** в правому верхньому куті
2. Клікніть на **When chat message received**
3. Скопіюйте **Production URL**
4. Відкрийте URL в браузері

### Крок 6: Тестування

**Тест 1: Перевірка пошуку**
```
Користувач: "Що є в базі знань про [тема з вашого PDF]?"
Очікується: Агент знаходить інформацію і відповідає
```

**Тест 2: Перевірка пам'яті**
```
Користувач: "Як мене звати?"
Агент: "Ви не сказали"
Користувач: "Мене звати Іван"
Агент: "Приємно познайомитись, Іван"
Користувач: "Як мене звати?"
Очікується: Агент пам'ятає ім'я
```

**Тест 3: Перевірка інформації з зображення**
```
Користувач: "Що ти знаєш про [тема з зображення]?"
Очікується: Агент використовує розпізнаний текст з картинки
```

---

## Типові проблеми та рішення

### Проблема: "Агент не знаходить інформацію з бази"

**Причини:**
- База не була заповнена
- Memory Key не збігається (перевірте що і Insert і Retrieve використовують `vector_store_key`)
- Текст розбитий на занадто великі chunk'и

**Рішення:**
1. Перезапустіть Data Ingestion workflow
2. Перевірте Memory Key в обох Vector Store нодах
3. Зменшіть Chunk Size до 500

### Проблема: "Embeddings OpenAI помилка"

**Рішення:**
- Перевірте API ключ
- Перевірте що модель embeddings однакова в обох нодах
- Перевірте баланс на OpenAI акаунті

### Проблема: "Analyze image не працює"

**Рішення:**
- Використовуйте модель `gpt-4o-mini` або `gpt-4o` (старі моделі не підтримують Vision)
- Перевірте що зображення завантажилось (перевірте binary data)
- Перевірте формат зображення (підтримується PNG, JPG, WebP)

### Проблема: "Чат не відкривається"

**Рішення:**
- Переконайтесь що workflow активований
- Перевірте що URL скопійований повністю
- Перевірте що n8n доступний з інтернету (для локальної версії використовуйте ngrok)

### Проблема: "База знань втрачається після перезапуску n8n"

**Пояснення:** Simple Vector Store зберігає дані в оперативній пам'яті

**Рішення:**
1. Після кожного перезапуску n8n запускайте Data Ingestion знову
2. АБО використовуйте persistent vector store:
   - Pinecone Vector Store (хмарне рішення)
   - Qdrant Vector Store (можна розгорнути локально)

---

## Розширення можливостей

### Додати більше джерел даних

**Веб-сторінки:**
Додайте **HTTP Request** + **HTML Extract** замість Extract from File

**Google Docs:**
Використайте **Google Docs** ноду

**Notion:**
Використайте **Notion** ноду

**Локальні файли:**
Замініть HTTP Request на **Read Binary File**

### Додати персистентну векторну базу

**Pinecone (рекомендується):**
1. Зареєструйтесь на https://www.pinecone.io/
2. Створіть Index
3. Замініть Simple Vector Store на **Pinecone Vector Store**
4. Вкажіть credentials

**Переваги:**
- Дані зберігаються назавжди
- Масштабування до мільйонів векторів
- Не треба перезаповнювати після перезапуску

### Додати голосовий ввід

1. Додайте **OpenAI Audio** ноду (Transcribe)
2. Підключіть до Chat Trigger
3. Конвертуйте аудіо в текст

### Додати мультимовність

В System Message:
```
Визначай мову запиту користувача і відповідай тією ж мовою.

Підтримуються: українська, англійська, польська.
```

### Додати аналітику

1. Після AI Agent додайте **Google Sheets** ноду
2. Зберігайте всі запити та відповіді
3. Аналізуйте популярні теми

---

## Корисні поради

### Оптимізація вартості

1. **Використовуйте gpt-4o-mini** замість gpt-4o (в 10 разів дешевше)
2. **Зменшіть Context Window** в Simple Memory до 10
3. **Зменшіть Top K** в Vector Store до 3
4. **Використовуйте text-embedding-3-small** замість ada-002

### Підвищення якості відповідей

1. **Збільшіть Top K** до 7-10 для складних запитів
2. **Покращіть якість даних** в базі знань:
   - Видаліть зайву інформацію
   - Структуруйте текст з заголовками
   - Додайте резюме на початку документів
3. **Налаштуйте Chunk Size**:
   - Для FAQ: 300-500
   - Для статей: 800-1000
   - Для технічної документації: 1000-1500

### Безпека

1. **Не публікуйте API ключі** в коді
2. **Обмежте доступ** до Chat URL (використовуйте автентифікацію n8n)
3. **Додайте rate limiting** якщо чат публічний

---

## Архітектура рішення

### In-Memory Vector Store

**Переваги:**
- Швидкий старт
- Безкоштовно
- Все в одному workflow

**Недоліки:**
- Втрачається після перезапуску
- Обмежений розмір (RAM)
- Не підходить для production

### Коли переходити на Pinecone/Qdrant:

- База знань > 1000 документів
- Потрібна персистентність
- Багато користувачів одночасно
- Production середовище

---

## Приклади використання

### 1. Технічна підтримка продукту
- Завантажте документацію у PDF
- Налаштуйте агента як технічного експерта
- Клієнти отримують миттєві відповіді 24/7

### 2. Освітній асистент
- Завантажте підручники та лекції
- Студенти можуть ставити питання
- Агент пояснює з прикладами

### 3. Внутрішня база знань компанії
- Завантажте процедури, інструкції, FAQ
- Співробітники швидко знаходять інформацію
- Зменшує навантаження на HR та підтримку

### 4. Персональний асистент для досліджень
- Завантажте наукові статті
- Задавайте питання по темі
- Отримуйте резюме та інсайти

---

## Ліцензія

Цей проект доступний для вільного використання та модифікації.

## Підтримка

Якщо виникли питання:
1. Перевірте налаштування кожної ноди
2. Подивіться логи виконання в n8n
3. Перегляньте документацію n8n: https://docs.n8n.io/
4. Документація LangChain: https://js.langchain.com/docs/
